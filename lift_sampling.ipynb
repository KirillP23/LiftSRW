{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-02T06:54:13.537933Z",
     "start_time": "2017-12-02T06:54:11.241516Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import networkx.algorithms.isomorphism as iso\n",
    "import sympy\n",
    "import random\n",
    "import time\n",
    "import itertools\n",
    "import math\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-02T06:54:30.644609Z",
     "start_time": "2017-12-02T06:54:30.115870Z"
    },
    "code_folding": [
     0,
     15,
     64,
     96,
     124
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def graphlet_list(N):\n",
    "    assert N > 0\n",
    "    foo = 1\n",
    "    loc_graphlet_list = {n: [] for n in range(1,N+1)}\n",
    "    while True:\n",
    "        G = nx.graph_atlas(foo)\n",
    "        n = G.number_of_nodes()\n",
    "        if n>N:\n",
    "            break\n",
    "        if nx.is_connected(G):\n",
    "            loc_graphlet_list[n].append(G)\n",
    "        foo += 1\n",
    "    return loc_graphlet_list\n",
    "    \n",
    "\n",
    "def find_type_match(T):\n",
    "    n = T.number_of_nodes()\n",
    "    if n==1:\n",
    "        return((0, {u: 0 for u in T.nodes()}))\n",
    "    if n==2:\n",
    "        return((0, {u: i for i,u in enumerate(T.nodes())}))\n",
    "    if n==3:\n",
    "        if T.number_of_edges()==2:\n",
    "            u0 = next((node for node in T.nodes() if T.degree(node)==2))\n",
    "            (u1,u2) = (node for node in T.neighbors(u0))\n",
    "            return((0, {u0: 0, u1: 1, u2: 2}))\n",
    "        if T.number_of_edges()==3:\n",
    "            return((1,{u:i for i,u in enumerate(T.nodes())}))\n",
    "    if n==4:\n",
    "        e_num = T.number_of_edges()\n",
    "        max_degree = max((T.degree(node) for node in T.nodes()))\n",
    "        if e_num==3 and max_degree==3:\n",
    "            u3 = next((node for node in T.nodes() if T.degree(node)==3))\n",
    "            (u0,u1,u2) = (node for node in T.neighbors(u3))\n",
    "            return((0, {u0:0, u1:1, u2:2, u3:3}))\n",
    "        if e_num==3 and max_degree==2:\n",
    "            (u0,u1) = (node for node in T.nodes() if T.degree(node)==2)\n",
    "            u2 = next((node for node in T.neighbors(u1) if node!=u0))\n",
    "            u3 = next((node for node in T.neighbors(u0) if node!=u1))\n",
    "            return((1, {u0:0, u1:1, u2:2, u3:3}))\n",
    "        if e_num==4 and max_degree==3:\n",
    "            u3 = next((node for node in T.nodes() if T.degree(node)==3))\n",
    "            (u1,u2) = (node for node in T.nodes() if T.degree(node)==2)\n",
    "            u0 = next((node for node in T.nodes() if T.degree(node)==1))\n",
    "            return((2, {u0:0, u1:1, u2:2, u3:3}))\n",
    "        if e_num==4 and max_degree==2:\n",
    "            u0 = next((node for node in T.nodes()))\n",
    "            (u1,u3) = (node for node in T.neighbors(u0))\n",
    "            u2 = next((node for node in T.neighbors(u1) if node!=u0))\n",
    "            return((3, {u0:0, u1:1, u2:2, u3:3}))\n",
    "        if e_num==5:\n",
    "            (u0,u2) = (node for node in T.nodes() if T.degree(node)==3)\n",
    "            (u1,u3) = (node for node in T.nodes() if T.degree(node)==2)\n",
    "            return((4, {u0:0, u1:1, u2:2, u3:3}))\n",
    "        if e_num==6:\n",
    "            (u0,u1,u2,u3) = (node for node in T.nodes())\n",
    "            return((5, {u0:0, u1:1, u2:2, u3:3}))\n",
    "    # Improve matching procedure here for n>4.\n",
    "    GM = next((i, iso.GraphMatcher(T,T_)) \n",
    "              for (i,T_) in enumerate(cached_graphlet_list[n]) \n",
    "              if iso.GraphMatcher(T,T_).is_isomorphic())\n",
    "    assert GM[1].is_isomorphic()\n",
    "    return((GM[0],GM[1].mapping))\n",
    "\n",
    "def find_type(T):\n",
    "    n = T.number_of_nodes()\n",
    "    if n==1:\n",
    "        return 0\n",
    "    if n==2:\n",
    "        return 0\n",
    "    if n==3:\n",
    "        if T.number_of_edges()==2:\n",
    "            return 0\n",
    "        if T.number_of_edges()==3:\n",
    "            return 1\n",
    "    if n==4:\n",
    "        e_num = T.number_of_edges()\n",
    "        max_degree = max((T.degree(node) for node in T.nodes()))\n",
    "        if e_num==3 and max_degree==3:\n",
    "            return 0\n",
    "        if e_num==3 and max_degree==2:\n",
    "            return 1\n",
    "        if e_num==4 and max_degree==3:\n",
    "            return 2\n",
    "        if e_num==4 and max_degree==2:\n",
    "            return 3\n",
    "        if e_num==5:\n",
    "            return 4\n",
    "        if e_num==6:\n",
    "            return 5\n",
    "    # Improve matching procedure here at least for n=4.\n",
    "    GM = next((i \n",
    "              for (i,T_) in enumerate(cached_graphlet_list[n]) \n",
    "              if iso.GraphMatcher(T,T_).is_isomorphic()))\n",
    "    return GM  \n",
    "\n",
    "def prob_functions(N):\n",
    "    assert N > 0\n",
    "    x = {0: sympy.var('x_0')}\n",
    "    y = {0: sympy.var('y_0')}\n",
    "    prob = {1: {0: x[0]/2}}\n",
    "    if N > 1:\n",
    "        x[1] = sympy.var('x_1')        \n",
    "        y[1] = sympy.var('y_1')\n",
    "        prob[2] = {0: sympy.Integer(1)}\n",
    "    for n in range(3, N+1):\n",
    "        x[n-1] = sympy.var('x_{}'.format(n-1))\n",
    "        y[n-1] = sympy.var('y_{}'.format(n-1))\n",
    "        prob[n] = {}\n",
    "        for T_ind, T in enumerate(cached_graphlet_list[n]):\n",
    "            prob[n][T_ind] = 0\n",
    "            for u in T.nodes():\n",
    "                S = subgraph(T, T.nodes()-{u})\n",
    "                if not nx.is_connected(S):\n",
    "                    continue\n",
    "                S_ind, S_match = find_type_match(S)\n",
    "                S_prob = (prob[n-1][S_ind]\n",
    "                          .subs({x[i]:y[i] for i in range(n-1)})\n",
    "                          .subs({y[j]:x[i] for i,j in S_match.items()})\n",
    "                         )\n",
    "                S_deg = sum(x[i] for i in S.nodes()) - 2*S.number_of_edges()\n",
    "                prob[n][T_ind] += S_prob * T.degree(u) / S_deg                 \n",
    "    return prob[N]\n",
    "\n",
    "def subgraph(G, nodes):\n",
    "    list_nodes = list(nodes)\n",
    "    T = nx.Graph()\n",
    "    T.add_nodes_from(nodes)\n",
    "    for i in range(len(nodes)):\n",
    "        for j in range(i):\n",
    "            if list_nodes[i] in G.neighbors(list_nodes[j]):\n",
    "                T.add_edge(list_nodes[i],list_nodes[j])\n",
    "    return T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-03T00:17:14.609191Z",
     "start_time": "2017-12-03T00:17:14.146510Z"
    }
   },
   "outputs": [],
   "source": [
    "k=4\n",
    "x = [sympy.var('x_{}'.format(i)) for i in range(k)]\n",
    "cached_graphlet_list = graphlet_list(k)\n",
    "cached_prob = {ind: sympy.lambdify(x, func) \n",
    "                    for ind, func in prob_functions(k).items()\n",
    "              }\n",
    "#4s for N=5, 2m43s for N=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-03T06:28:15.451088Z",
     "start_time": "2017-12-03T06:28:14.183450Z"
    },
    "code_folding": [
     13,
     19,
     86,
     124,
     130,
     134,
     137
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lift(G, vert, k):\n",
    "    graphlet = set([vert])\n",
    "    if k==1:\n",
    "        return graphlet\n",
    "    u = vert\n",
    "    neig_list = []\n",
    "    for n in range(2, k+1):\n",
    "        neig_list = ([v for v in neig_list if v!=u] \n",
    "                     + [v for v in G.neighbors(u) if v not in graphlet])\n",
    "        u = random.choice(neig_list)\n",
    "        graphlet.add(u)\n",
    "    return graphlet\n",
    "\n",
    "def random_walk_nodes(G, v0, steps_num):\n",
    "    curr_vert = v0\n",
    "    for _ in range(steps_num):\n",
    "        curr_vert = random.choice(list(G.neighbors(curr_vert)))\n",
    "    return curr_vert\n",
    "\n",
    "def liftSRW(G, k, time_limit=None, query_limit=None, epoch_num=1, time_step=10, \n",
    "            output_form='count', ground_truth=None, steps_mult=None, steps_num=None):\n",
    "\n",
    "    assert (time_limit is None) != (query_limit is None)\n",
    "    assert (steps_mult is None) != (steps_num is None)\n",
    "    \n",
    "    if steps_mult is not None:\n",
    "        steps_between_lifts = int(steps_mult*math.log(G.number_of_nodes()))\n",
    "    else:\n",
    "        steps_between_lifts = steps_num\n",
    "    norm_error = 0\n",
    "    \n",
    "    for epoch in range(epoch_num):\n",
    "        #print('Starting epoch {}'.format(epoch+1))\n",
    "        type_counter = {i:0 for i in range(len(cached_graphlet_list[k]))}\n",
    "        t0 = time.time()\n",
    "        lift_count = 0\n",
    "        query_count = 0\n",
    "        time_iter_count = 1\n",
    "        stop_condition = False\n",
    "        v = random.choice(list(G.nodes()))\n",
    "        flag = 0\n",
    "\n",
    "        while not stop_condition:\n",
    "            v = random_walk_nodes(G, v, steps_between_lifts)\n",
    "            T = lift(G, v, k)\n",
    "            T_type, T_match = find_type_match(subgraph(G,T))\n",
    "            inv_match = {i: j for j,i in T_match.items()}\n",
    "            degree_list = [G.degree(inv_match[i]) for i in range(k)]\n",
    "            T_prob = cached_prob[T_type](*degree_list)\n",
    "            type_counter[T_type] += (T_prob)**(-1)\n",
    "            lift_count += 1\n",
    "            curr_time = time.time()\n",
    "            type_list = []\n",
    "            \n",
    "            if curr_time - t0 > time_iter_count*time_step:\n",
    "                if output_form=='count':\n",
    "                    print(\"Time is {} Type counter is {}\"\n",
    "                          .format(int(curr_time-t0), \n",
    "                                  scale(type_counter, \n",
    "                                        G.number_of_edges()*lift_count**(-1))))\n",
    "                if output_form=='ratio':\n",
    "                    print(\"Time is {} Type ratios are {}\"\n",
    "                          .format(int(curr_time-t0), \n",
    "                                  normalize(type_counter)))\n",
    "                print(\"Time is {} NMSE is {}\"\n",
    "                      .format(int(curr_time-t0), \n",
    "                              NMSE(type_counter, ground_truth)))\n",
    "                print(\"Number of graphlets sampled is {}\".format(lift_count))\n",
    "                time_iter_count += 1\n",
    "                \n",
    "            if time_limit is not None:\n",
    "                stop_condition = (time.time()-t0 > time_limit)\n",
    "            if query_limit is not None:\n",
    "                query_count += steps_between_lifts + k - 1\n",
    "                stop_condition = (query_count > query_limit)\n",
    "\n",
    "        if ground_truth is not None:\n",
    "            error = NMSE(type_counter, ground_truth)\n",
    "            #print(\"NMSE error is {}\".format(error))\n",
    "            norm_error += error\n",
    "        #print(\"\")\n",
    "    print(\"Number of lifts is {}\".format(lift_count))\n",
    "    norm_error = norm_error*(epoch_num)**(-1)\n",
    "    return {'count': scale(type_counter, G.number_of_edges()*lift_count**(-1)), \n",
    "            'NMSE': norm_error}\n",
    "\n",
    "def brute_force(G, N=3):\n",
    "    type_counter = {i:0 for i in range(len(cached_graphlet_list[N]))}\n",
    "    if N==3:\n",
    "        percent_count = 0\n",
    "        counter = 0\n",
    "        for u,v in G.edges():\n",
    "            for w in set(G.neighbors(u))-{v}:\n",
    "                if w in G.neighbors(v): \n",
    "                    type_counter[1] += 1\n",
    "                else:\n",
    "                    type_counter[0] += 1\n",
    "            for w in set(G.neighbors(v))-{u}:\n",
    "                if w in G.neighbors(u): \n",
    "                    type_counter[1] += 1\n",
    "                else:\n",
    "                    type_counter[0] += 1\n",
    "            counter += 1\n",
    "            if counter > percent_count*0.00001*G.number_of_edges():\n",
    "                clear_output()\n",
    "                #print(\"{}% complete\".format(percent_count*0.001))\n",
    "                percent_count += 1\n",
    "        type_counter[0] = type_counter[0]/2\n",
    "        type_counter[1] = type_counter[1]/6\n",
    "        \n",
    "    if N==4:\n",
    "        for u,v in G.edges():\n",
    "            neigh = set(G.neighbors(u)).union(set(G.neighbors(v)))-{u,v}\n",
    "            for w,z in itertools.combinations(neigh, 2):\n",
    "                T = subgraph(G, {u,v,w,z})\n",
    "                type_counter[find_type(T)] += 1\n",
    "        type_counter[0] = type_counter[0]/3\n",
    "        type_counter[1] = type_counter[1]\n",
    "        type_counter[2] = type_counter[2]/3\n",
    "        type_counter[3] = type_counter[3]/4\n",
    "        type_counter[4] = type_counter[4]/5\n",
    "        type_counter[5] = type_counter[5]/6\n",
    "    return type_counter\n",
    "\n",
    "def NMSE(dict_hat, dict_true):\n",
    "    norm_dict_hat = normalize(dict_hat)\n",
    "    norm_dict_true = normalize(dict_true)\n",
    "    return sum(((norm_dict_hat[i]*freq**(-1) - 1)**2\n",
    "                for i, freq in norm_dict_true.items() if freq != 0))\n",
    "\n",
    "def normalize(dict_hat):\n",
    "    total_count = sum((val for i,val in dict_hat.items()))\n",
    "    return {i: val*(total_count)**(-1) for i,val in dict_hat.items()}\n",
    "\n",
    "def scale(dict_hat, scalar):\n",
    "    return {i: int(val*scalar) for i,val in dict_hat.items()}\n",
    "\n",
    "def load_graph(name, k=3):\n",
    "    \n",
    "    ground_truth = None\n",
    "    G = None\n",
    "\n",
    "    if name=='com-amazon':\n",
    "        G = nx.read_edgelist(\n",
    "            'Graphs/com-amazon.ungraph.txt',\n",
    "            create_using = nx.Graph())\n",
    "        \n",
    "        if k==3:\n",
    "            ground_truth = {0: 7750799, \n",
    "                            1: 667129}\n",
    "        if k==4:\n",
    "            ground_truth = {0: 124295537, \n",
    "                            1: 37383434, \n",
    "                            2: 13674662, \n",
    "                            3: 422515, \n",
    "                            4: 1874925, \n",
    "                            5: 275961}\n",
    "\n",
    "    if name=='com-dblp':\n",
    "        G = nx.read_edgelist(\n",
    "            'Graphs/com-dblp.ungraph.txt',\n",
    "            create_using = nx.Graph())\n",
    "        if k==3:\n",
    "            ground_truth = {0: 15107734, \n",
    "                            1: 2224385}\n",
    "        if k==4:\n",
    "            ground_truth = {0: 258570802, \n",
    "                            1: 252447350, \n",
    "                            2: 96615211, \n",
    "                            3: 203394, \n",
    "                            4: 4764685, \n",
    "                            5: 16713192}\n",
    "\n",
    "    if name=='com-lj':\n",
    "        G = nx.read_edgelist(\n",
    "            'Graphs/com-lj.ungraph.txt',\n",
    "            create_using = nx.Graph())\n",
    "        if k==3:\n",
    "            ground_truth = {0: 3722307805, \n",
    "                            1: 177820130}\n",
    "        if k==4:\n",
    "            ground_truth = {0: 1983908933796,\n",
    "                            1: 542683013686,\n",
    "                            2: 57662704306,\n",
    "                            3: 2541452010,\n",
    "                            4: 8190586835,\n",
    "                            5: 521691844}\n",
    "\n",
    "    if name=='com-youtube':\n",
    "        G = nx.read_edgelist(\n",
    "            'Graphs/com-youtube.ungraph.txt',\n",
    "            create_using = nx.Graph())\n",
    "        if k==3:\n",
    "            ground_truth = {0: 1465313402, \n",
    "                            1: 3056386}\n",
    "        if k==4:\n",
    "            ground_truth = {0: 5730407268993,\n",
    "                            1: 91488735459,\n",
    "                            2: 12371157628,\n",
    "                            3: 231979854,\n",
    "                            4: 221833272,\n",
    "                            5: 4986965}\n",
    "\n",
    "    if name=='misc-net25':\n",
    "        G = nx.read_edgelist(\n",
    "            'Graphs/misc-net25.mtx',\n",
    "            create_using = nx.Graph())\n",
    "        for v in G.nodes():\n",
    "            G.remove_edge(v,v)\n",
    "        if k==3:\n",
    "            ground_truth = {0: 12690840, \n",
    "                            1: 64090}\n",
    "        if k==4:\n",
    "            ground_truth = {0: 361490550,\n",
    "                            1: 550792350,\n",
    "                            2: 12554670,\n",
    "                            3: 44915955,\n",
    "                            4: 0,\n",
    "                            5: 0}\n",
    "\n",
    "    if name=='bio-celegansneural':\n",
    "        G = nx.read_edgelist(\n",
    "            'Graphs/bio-celegansneural.mtx',\n",
    "            create_using = nx.Graph(), data=(('weight',float),))\n",
    "\n",
    "    if name=='bio-yeast':\n",
    "        G = nx.read_edgelist(\n",
    "            'Graphs/bio-yeast.mtx',\n",
    "            create_using = nx.Graph())\n",
    "    \n",
    "    if name=='bn-macaque-rhesus_brain_1':\n",
    "        G = nx.read_edgelist(\n",
    "            'Graphs/bn-macaque-rhesus_brain_1.edges',\n",
    "            create_using = nx.Graph())\n",
    "    \n",
    "    if name=='bn-mouse_brain_1':\n",
    "        G = nx.read_edgelist(\n",
    "            'Graphs/bn-mouse_brain_1.edges',\n",
    "            create_using = nx.Graph())\n",
    "    \n",
    "    if name=='ia-email-univ':\n",
    "        G = nx.read_edgelist(\n",
    "            'Graphs/ia-email-univ.mtx',\n",
    "            create_using = nx.Graph())\n",
    "\n",
    "    if name=='misc-polblogs':\n",
    "        G = nx.read_edgelist(\n",
    "            'Graphs/misc-polblogs.mtx',\n",
    "            create_using = nx.Graph(), data=(('weight',float),))\n",
    "        \n",
    "\n",
    "    if name=='misc-as-caida':\n",
    "        G = nx.read_edgelist(\n",
    "            'Graphs/misc-as-caida.mtx',\n",
    "            create_using = nx.Graph(), data=(('weight',float),)) \n",
    "        if k==3:\n",
    "            ground_truth = {0: 59513652, \n",
    "                            1: 72730}\n",
    "        if k==4:\n",
    "            ground_truth = {0: 62565214368,\n",
    "                            1: 2808802860,\n",
    "                            2: 203097552,\n",
    "                            3: 3774144,\n",
    "                            4: 4084544,\n",
    "                            5: 0}\n",
    "\n",
    "    if name=='misc-fullb':\n",
    "        G = nx.read_edgelist(\n",
    "            'Graphs/misc-fullb.mtx',\n",
    "            create_using = nx.Graph())\n",
    "        for v in G.nodes():\n",
    "            G.remove_edge(v,v)\n",
    "        if k==3:\n",
    "            ground_truth = {0: 162067420, \n",
    "                            1: 60212260}\n",
    "        if k==4:\n",
    "            ground_truth = {0: 1078734774,\n",
    "                            1: 4837795036,\n",
    "                            2: 2707584768,\n",
    "                            3: 64898820,\n",
    "                            4: 897215295,\n",
    "                            5: 370980150}\n",
    "\n",
    "    if name=='misc-neos3':\n",
    "        G = nx.read_edgelist(\n",
    "            'Graphs/misc-neos3.mtx',\n",
    "            create_using = nx.Graph(), data=(('weight',float),))\n",
    "\n",
    "        if k==3:\n",
    "            ground_truth = {0: 207426691, \n",
    "                            1: 505603}\n",
    "        if k==4:\n",
    "            ground_truth = {0: 59618248397,\n",
    "                            1: 11164704825,\n",
    "                            2: 120388385,\n",
    "                            3: 2047846,\n",
    "                            4: 499122,\n",
    "                            5: 0}\n",
    "\n",
    "    if name=='misc-discogs_affiliation':\n",
    "        G = nx.read_edgelist(\n",
    "            'Graphs/misc-discogs_affiliation.edges',\n",
    "            create_using = nx.Graph())\n",
    "        if k==3:\n",
    "            ground_truth = None\n",
    "        if k==4:\n",
    "            ground_truth = {0: 208345722513295,\n",
    "                            1: 851118877585,\n",
    "                            2: 58223406336,\n",
    "                            3: 3008868833,\n",
    "                            4: 439215089,\n",
    "                            5: 654413}\n",
    "\n",
    "    if name=='misc-amazon-ratings':\n",
    "        G = nx.read_edgelist(\n",
    "            'Graphs/misc-amazon-ratings.edges',\n",
    "            create_using = nx.Graph())\n",
    "        if k==3:\n",
    "            ground_truth = {0: 699425719, \n",
    "                            1: 79638}\n",
    "        if k==4:\n",
    "            ground_truth = {0: 719668204837,\n",
    "                            1: 40966346985,\n",
    "                            2: 184396006,\n",
    "                            3: 37045086,\n",
    "                            4: 561566,\n",
    "                            5: 671}\n",
    "\n",
    "    if name=='misc-dbpedia-all':\n",
    "        G = nx.read_edgelist(\n",
    "            'Graphs/misc-dbpedia-all.edges',\n",
    "            create_using = nx.Graph())\n",
    "        if k==3:\n",
    "            ground_truth = {0: 174250340949, \n",
    "                            1: 8329548}\n",
    "        if k==4:\n",
    "            ground_truth = {0: 19646604300441472,\n",
    "                            1: 1652259549599,\n",
    "                            2: 622928133900,\n",
    "                            3: 15925209557,\n",
    "                            4: 15630164176,\n",
    "                            5: 4609834}\n",
    "            \n",
    "    if G is None:\n",
    "        raise KeyError\n",
    "\n",
    "    return {'graph': G, 'ground_truth': ground_truth}\n",
    "\n",
    "def lift_mixing(G, k, steps_num=1000, burn_in_limit=20):\n",
    "    v = random_walk_nodes(G,random.choice(list(G.nodes())),100)\n",
    "    graphlet_num = len(cached_graphlet_list[k])\n",
    "    type_counter = {i:0 for i in range(graphlet_num)}\n",
    "    pair_counter = {burn_in: \n",
    "                    {i: [0]*graphlet_num \n",
    "                     for i in range(graphlet_num)} \n",
    "                    for burn_in in range(0,burn_in_limit)}\n",
    "    memory = [None for _ in range(burn_in_limit)]\n",
    "    for _ in range(steps_num):\n",
    "        T = lift(G, v, k)\n",
    "        v = random_walk_nodes(G, v, 1)\n",
    "        T_type = find_type(subgraph(G, T))\n",
    "        type_counter[T_type] += 1\n",
    "        ind = 0\n",
    "        while ind < burn_in_limit and memory[ind] is not None:\n",
    "            pair_counter[ind][memory[ind]][T_type] += 1\n",
    "            ind+=1\n",
    "        memory = [T_type] + memory[:-1]\n",
    "    type_prob = [type_counter[i]*steps_num**(-1) \n",
    "                 for i in range(graphlet_num)]\n",
    "    beta_coeff = [0]*burn_in_limit\n",
    "    for burn_in in range(burn_in_limit):\n",
    "        TV = {}\n",
    "        for i in range(graphlet_num):\n",
    "            cond_counter = pair_counter[burn_in][i] \n",
    "            cond_total = sum(cond_counter)\n",
    "            if cond_total==0:\n",
    "                TV[i] = 0 if type_prob==0 else 1\n",
    "                continue\n",
    "            cond_prob = [foo*cond_total**(-1) \n",
    "                         for foo in cond_counter]\n",
    "            TV[i] = sum((abs(cond_prob[j] - type_prob[j]) \n",
    "                        for j in range(graphlet_num)))/2\n",
    "        beta_coeff[burn_in] = sum((TV[i]*type_prob[i] \n",
    "                                   for i in range(graphlet_num)))\n",
    "    return beta_coeff\n",
    "\n",
    "def lift_variance(G, k, steps_num=1000, burn_in=3):\n",
    "    v = random_walk_nodes(G,random.choice(list(G.nodes())),100)\n",
    "    graphlet_num = len(cached_graphlet_list[k])\n",
    "    variance_counter = {i:0 for i in range(graphlet_num)}\n",
    "    expectation_counter = {i:0 for i in range(graphlet_num)}\n",
    "    for _ in range(steps_num):\n",
    "        T = lift(G, v, k)\n",
    "        T_type, T_match = find_type_match(subgraph(G,T))\n",
    "        inv_match = {i: j for j,i in T_match.items()}\n",
    "        degree_list = [G.degree(inv_match[i]) for i in range(k)]\n",
    "        T_prob = cached_prob[T_type](*degree_list)*(G.number_of_edges())**(-1)\n",
    "        expectation_counter[T_type] += (T_prob)**(-1)\n",
    "        variance_counter[T_type] += (T_prob)**(-2)\n",
    "        v = random_walk_nodes(G,v,burn_in)\n",
    "    norm_variance = {i: (variance_counter[i]**(0.5)\n",
    "                         * expectation_counter[i]**(-1) \n",
    "                         * steps_num**(0.5))\n",
    "                     for i in range(graphlet_num) \n",
    "                     if expectation_counter[i]!=0}\n",
    "    return norm_variance\n",
    "\n",
    "def lift_count(G, k, steps_num=1000, burn_in=3):\n",
    "    v = random_walk_nodes(G,random.choice(list(G.nodes())),100)\n",
    "    graphlet_num = len(cached_graphlet_list[k])\n",
    "    graphlet_counter = {i:0 for i in range(graphlet_num)}\n",
    "    for _ in range(steps_num):\n",
    "        T = lift(G, v, k)\n",
    "        T_type, T_match = find_type_match(subgraph(G,T))\n",
    "        inv_match = {i: j for j,i in T_match.items()}\n",
    "        degree_list = [G.degree(inv_match[i]) for i in range(k)]\n",
    "        T_prob = cached_prob[T_type](*degree_list)*(G.number_of_edges())**(-1)\n",
    "        graphlet_counter[T_type] += (T_prob)**(-1)\n",
    "        v = random_walk_nodes(G,v,burn_in)\n",
    "    graphlet_counter = {i: var*steps_num**(-1) \n",
    "                        for i,var in graphlet_counter.items()}\n",
    "    return graphlet_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-03T06:31:25.539258Z",
     "start_time": "2017-12-03T06:31:24.099009Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26475, 53381)\n"
     ]
    }
   ],
   "source": [
    "G = load_graph('misc-as-caida',4)['graph']\n",
    "print(G.number_of_nodes(), G.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-03T06:36:29.738084Z",
     "start_time": "2017-12-03T06:31:25.542907Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 2.246544150272723,\n",
       " 1: 8.531503943006276,\n",
       " 2: 13.617623312459154,\n",
       " 3: 39.58691085843351,\n",
       " 4: 56.92299418108377,\n",
       " 5: 99.93928997754834}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lift_variance(G, 4, steps_num=10**4, burn_in=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-03T06:41:07.037582Z",
     "start_time": "2017-12-03T06:36:29.741934Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 7873732655.898591,\n",
       " 1: 271514189.0965111,\n",
       " 2: 39983265.322642274,\n",
       " 3: 604482.6347905787,\n",
       " 4: 885057.7932221919,\n",
       " 5: 49889.67927453778}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lift_count(G, 4, steps_num=10**4, burn_in=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-03T00:20:58.448610Z",
     "start_time": "2017-12-03T00:18:21.748535Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.009565372020277924,\n",
       " 0.006972877951632002,\n",
       " 0.004512160263764676,\n",
       " 0.003445393895565365,\n",
       " 0.0028895610582789877,\n",
       " 0.0026080105160266407,\n",
       " 0.0020466869826976475,\n",
       " 0.002409575929643989,\n",
       " 0.0018202535804742255,\n",
       " 0.0015824779405675408,\n",
       " 0.0015578331428171108,\n",
       " 0.001669066715933854,\n",
       " 0.0018406780533377694,\n",
       " 0.001675254494588011,\n",
       " 0.0014685979874825158,\n",
       " 0.0014740082547587145,\n",
       " 0.0014631860180295514,\n",
       " 0.0014501770728314724,\n",
       " 0.0016311790760082977,\n",
       " 0.0019556711428454503]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lift_mixing(G, 4, steps_num=10**6, burn_in_limit=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
